{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install and Import Libraries","metadata":{}},{"cell_type":"code","source":"!pip install datasets transformers[sentencepiece] sacrebleu -q tokenizers evaluate rouge_score torch huggingface_hub -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-02T07:59:02.780839Z","iopub.execute_input":"2025-05-02T07:59:02.781473Z","iopub.status.idle":"2025-05-02T08:00:13.877693Z","shell.execute_reply.started":"2025-05-02T07:59:02.781451Z","shell.execute_reply":"2025-05-02T08:00:13.876975Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport sys\nimport transformers\nimport tensorflow as tf\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer\nfrom transformers import TFAutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\nfrom transformers import AdamWeightDecay\nfrom transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:00:13.879130Z","iopub.execute_input":"2025-05-02T08:00:13.879414Z","iopub.status.idle":"2025-05-02T08:00:36.936402Z","shell.execute_reply.started":"2025-05-02T08:00:13.879391Z","shell.execute_reply":"2025-05-02T08:00:36.935852Z"}},"outputs":[{"name":"stderr","text":"2025-05-02 08:00:19.281906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746172819.486177      40 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746172819.542679      40 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Load Model and Dataset","metadata":{}},{"cell_type":"code","source":"model_checkpoint = \"Helsinki-NLP/opus-mt-en-de\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:00:36.937241Z","iopub.execute_input":"2025-05-02T08:00:36.938355Z","iopub.status.idle":"2025-05-02T08:00:36.942365Z","shell.execute_reply.started":"2025-05-02T08:00:36.938327Z","shell.execute_reply":"2025-05-02T08:00:36.941460Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"datasets = load_dataset(\"Darth-Vaderr/English-German\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:00:36.944194Z","iopub.execute_input":"2025-05-02T08:00:36.944420Z","iopub.status.idle":"2025-05-02T08:07:47.602114Z","shell.execute_reply.started":"2025-05-02T08:00:36.944403Z","shell.execute_reply":"2025-05-02T08:07:47.601523Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/2.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a120a7353646eba7f129ec5029958d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"FT_Dataset.jsonl:   0%|          | 0.00/13.3G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4a1f0c88c694e75b68d7ddc8877e27a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Final_Dataset_v3.jsonl:   0%|          | 0.00/13.3G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18a07187cd8e403db50c284e9a4e9df3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f652f779031d4001a18a4ec8028ab5a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/47 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d26f389539740aebb126782548216fa"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:07:47.603395Z","iopub.execute_input":"2025-05-02T08:07:47.603714Z","iopub.status.idle":"2025-05-02T08:07:47.608482Z","shell.execute_reply.started":"2025-05-02T08:07:47.603687Z","shell.execute_reply":"2025-05-02T08:07:47.607946Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['German', 'English'],\n        num_rows: 97329967\n    })\n})"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"datasets['train'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:07:47.609299Z","iopub.execute_input":"2025-05-02T08:07:47.609550Z","iopub.status.idle":"2025-05-02T08:07:47.634198Z","shell.execute_reply.started":"2025-05-02T08:07:47.609529Z","shell.execute_reply":"2025-05-02T08:07:47.633602Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'German': 'Ich erkläre die am Freitag, dem 15. Dezember 2000, unterbrochene Sitzungsperiode des Europäischen Parlaments für wieder aufgenommen.',\n 'English': 'I declare resumed the session of the European Parliament adjourned on Friday, 15 December 2000.'}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from datasets import DatasetDict\nshuffled = datasets['train'].shuffle(seed=42)\n\n# Step 2: Split into train (15000), validation (1000), test (1000)\ntrain_sample = shuffled.select(range(15000))\nval_sample = shuffled.select(range(15000, 16000))\ntest_sample = shuffled.select(range(16000, 17000))\n\n# Step 3: Create a new DatasetDict with the samples\nsmall_dataset = DatasetDict({\n    'train': train_sample,\n    'validation': val_sample,\n    'test': test_sample\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:07:47.634791Z","iopub.execute_input":"2025-05-02T08:07:47.634945Z","iopub.status.idle":"2025-05-02T08:08:18.991148Z","shell.execute_reply.started":"2025-05-02T08:07:47.634933Z","shell.execute_reply":"2025-05-02T08:08:18.990583Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"small_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:08:18.991874Z","iopub.execute_input":"2025-05-02T08:08:18.992100Z","iopub.status.idle":"2025-05-02T08:08:18.997135Z","shell.execute_reply.started":"2025-05-02T08:08:18.992085Z","shell.execute_reply":"2025-05-02T08:08:18.996423Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['German', 'English'],\n        num_rows: 15000\n    })\n    validation: Dataset({\n        features: ['German', 'English'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['German', 'English'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"small_dataset['train'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:08:18.997835Z","iopub.execute_input":"2025-05-02T08:08:18.998051Z","iopub.status.idle":"2025-05-02T08:08:19.014515Z","shell.execute_reply.started":"2025-05-02T08:08:18.998036Z","shell.execute_reply":"2025-05-02T08:08:19.013850Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'German': 'Da noch nicht jeder das Konzept kennt, muss den Teilnehmern in einer Einleitung das Prozedere und dessen Eigenheiten erläutert werden.',\n 'English': 'Since not everyone is familiar with this concept, the procedure and its peculiarities must be explained to the participants.'}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:08:19.017304Z","iopub.execute_input":"2025-05-02T08:08:19.017534Z","iopub.status.idle":"2025-05-02T08:08:20.344162Z","shell.execute_reply.started":"2025-05-02T08:08:19.017520Z","shell.execute_reply":"2025-05-02T08:08:20.343418Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97c01b6f22214bb0840f6d30e4163e6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b718ae66b8714209965ebe45e81cbd60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/768k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a1f481a1ab04484833df5af8a38d9f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/797k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bff813fa8a2f4a5791ee5e9dbfb67ced"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82b74a24ef454b1184c5b706a164f39d"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"tokenizer(\"Hello, this is a sentence!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:08:20.344786Z","iopub.execute_input":"2025-05-02T08:08:20.344990Z","iopub.status.idle":"2025-05-02T08:08:20.350288Z","shell.execute_reply.started":"2025-05-02T08:08:20.344974Z","shell.execute_reply":"2025-05-02T08:08:20.349510Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [16816, 2, 60, 19, 14, 12512, 68, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"with tokenizer.as_target_tokenizer():\n    print(tokenizer([\"Ich komme aus banha\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:08:20.351251Z","iopub.execute_input":"2025-05-02T08:08:20.352002Z","iopub.status.idle":"2025-05-02T08:08:20.365491Z","shell.execute_reply.started":"2025-05-02T08:08:20.351985Z","shell.execute_reply":"2025-05-02T08:08:20.364802Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': [[105, 9158, 74, 17, 6848, 1803, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1]]}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"max_input_length = 128\nmax_target_length = 128\n\nsource_lang = \"English\"\ntarget_lang = \"German\"\n\n\ndef preprocess_function(examples):\n    inputs = [sentence for sentence in examples[source_lang]]\n    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n\n    # Tokenize the targets (highlights)\n    labels = tokenizer(\n        text_target=examples[target_lang],\n        max_length=max_target_length,\n        truncation=True,\n    )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:08:20.366163Z","iopub.execute_input":"2025-05-02T08:08:20.366448Z","iopub.status.idle":"2025-05-02T08:08:20.373829Z","shell.execute_reply.started":"2025-05-02T08:08:20.366432Z","shell.execute_reply":"2025-05-02T08:08:20.373112Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\n# Apply preprocessing to each split\ntokenized_dataset = {\n    split: ds.map(preprocess_function, batched=True)\n    for split, ds in small_dataset.items()\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:08:20.374537Z","iopub.execute_input":"2025-05-02T08:08:20.374831Z","iopub.status.idle":"2025-05-02T08:08:56.455516Z","shell.execute_reply.started":"2025-05-02T08:08:20.374816Z","shell.execute_reply":"2025-05-02T08:08:56.454761Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aa73ca381184e4694cab579699345fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e609cd13b18f4cbc8be61b4f9644c8e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5567747ad2984a64b04d87ee510e0b7a"}},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:08:56.456605Z","iopub.execute_input":"2025-05-02T08:08:56.456845Z","iopub.status.idle":"2025-05-02T08:09:02.225153Z","shell.execute_reply.started":"2025-05-02T08:08:56.456819Z","shell.execute_reply":"2025-05-02T08:09:02.224334Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/298M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2c7c85953574e4a98b0b6555d95d12d"}},"metadata":{}},{"name":"stderr","text":"I0000 00:00:1746173338.547583      40 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1746173338.548252      40 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\nAll model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-de.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84a1f994e8174b6db0cf35e759314614"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:09:02.226043Z","iopub.execute_input":"2025-05-02T08:09:02.226307Z","iopub.status.idle":"2025-05-02T08:09:02.230443Z","shell.execute_reply.started":"2025-05-02T08:09:02.226284Z","shell.execute_reply":"2025-05-02T08:09:02.229610Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"generation_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"tf\", pad_to_multiple_of=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:09:02.231264Z","iopub.execute_input":"2025-05-02T08:09:02.231626Z","iopub.status.idle":"2025-05-02T08:09:02.242385Z","shell.execute_reply.started":"2025-05-02T08:09:02.231602Z","shell.execute_reply":"2025-05-02T08:09:02.241715Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"batch_size = 16\nlearning_rate = 2e-5\nweight_decay = 0.01\nnum_train_epochs = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:09:02.243143Z","iopub.execute_input":"2025-05-02T08:09:02.243401Z","iopub.status.idle":"2025-05-02T08:09:02.254456Z","shell.execute_reply.started":"2025-05-02T08:09:02.243379Z","shell.execute_reply":"2025-05-02T08:09:02.253733Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"train_dataset = model.prepare_tf_dataset(\n    tokenized_dataset[\"train\"],\n    batch_size=batch_size,\n    shuffle=True,\n    collate_fn=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:09:02.255238Z","iopub.execute_input":"2025-05-02T08:09:02.255476Z","iopub.status.idle":"2025-05-02T08:09:03.402138Z","shell.execute_reply.started":"2025-05-02T08:09:02.255456Z","shell.execute_reply":"2025-05-02T08:09:03.401608Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"validation_dataset = model.prepare_tf_dataset(\n    tokenized_dataset[\"validation\"],\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn=data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:09:03.403141Z","iopub.execute_input":"2025-05-02T08:09:03.403362Z","iopub.status.idle":"2025-05-02T08:09:03.573936Z","shell.execute_reply.started":"2025-05-02T08:09:03.403345Z","shell.execute_reply":"2025-05-02T08:09:03.573436Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"generation_dataset = model.prepare_tf_dataset(\n    tokenized_dataset[\"test\"],\n    batch_size=8,\n    shuffle=False,\n    collate_fn=generation_data_collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:09:03.574720Z","iopub.execute_input":"2025-05-02T08:09:03.574887Z","iopub.status.idle":"2025-05-02T08:09:03.741438Z","shell.execute_reply.started":"2025-05-02T08:09:03.574874Z","shell.execute_reply":"2025-05-02T08:09:03.740907Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)\nmodel.compile(optimizer=optimizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:09:03.742396Z","iopub.execute_input":"2025-05-02T08:09:03.742638Z","iopub.status.idle":"2025-05-02T08:09:03.756773Z","shell.execute_reply.started":"2025-05-02T08:09:03.742617Z","shell.execute_reply":"2025-05-02T08:09:03.756071Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model.fit(train_dataset, validation_data=validation_dataset, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:09:03.757446Z","iopub.execute_input":"2025-05-02T08:09:03.757701Z","iopub.status.idle":"2025-05-02T08:34:55.712183Z","shell.execute_reply.started":"2025-05-02T08:09:03.757685Z","shell.execute_reply":"2025-05-02T08:34:55.711624Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n937/937 [==============================] - 343s 324ms/step - loss: 1.6781 - val_loss: 1.5920\nEpoch 2/5\n937/937 [==============================] - 304s 324ms/step - loss: 1.4805 - val_loss: 1.6056\nEpoch 3/5\n937/937 [==============================] - 302s 322ms/step - loss: 1.3280 - val_loss: 1.6262\nEpoch 4/5\n937/937 [==============================] - 301s 322ms/step - loss: 1.1950 - val_loss: 1.6540\nEpoch 5/5\n937/937 [==============================] - 302s 322ms/step - loss: 1.0816 - val_loss: 1.6835\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7beaa4647bd0>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"model.save_pretrained(\"./tf_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:44:25.070945Z","iopub.execute_input":"2025-05-02T08:44:25.071459Z","iopub.status.idle":"2025-05-02T08:44:26.538745Z","shell.execute_reply.started":"2025-05-02T08:44:25.071437Z","shell.execute_reply":"2025-05-02T08:44:26.537902Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[58100]]}\n  warnings.warn(\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"tokenizer.save_pretrained(\"./tok_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:53:40.543791Z","iopub.execute_input":"2025-05-02T08:53:40.544073Z","iopub.status.idle":"2025-05-02T08:53:40.594372Z","shell.execute_reply.started":"2025-05-02T08:53:40.544053Z","shell.execute_reply":"2025-05-02T08:53:40.593787Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"('./tok_model/tokenizer_config.json',\n './tok_model/special_tokens_map.json',\n './tok_model/vocab.json',\n './tok_model/source.spm',\n './tok_model/target.spm',\n './tok_model/added_tokens.json')"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"# Model Testing","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\nmodel = TFAutoModelForSeq2SeqLM.from_pretrained(\"./tf_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:44:28.327295Z","iopub.execute_input":"2025-05-02T08:44:28.327732Z","iopub.status.idle":"2025-05-02T08:44:30.882785Z","shell.execute_reply.started":"2025-05-02T08:44:28.327709Z","shell.execute_reply":"2025-05-02T08:44:30.882226Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\nAll model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at ./tf_model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"input_text  = \"My name is Ziad. I am twenty two years old\"\n\ntokenized = tokenizer([input_text], return_tensors='np')\nout = model.generate(**tokenized, max_length=128)\nprint(out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:44:32.267201Z","iopub.execute_input":"2025-05-02T08:44:32.267455Z","iopub.status.idle":"2025-05-02T08:44:36.204023Z","shell.execute_reply.started":"2025-05-02T08:44:32.267436Z","shell.execute_reply":"2025-05-02T08:44:36.203283Z"}},"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[58100  1701  1282    29  5657  1183     3   105   495   338 29263   431\n   3283     0 58100]], shape=(1, 15), dtype=int32)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"with tokenizer.as_target_tokenizer():\n    print(tokenizer.decode(out[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T08:44:37.659216Z","iopub.execute_input":"2025-05-02T08:44:37.659914Z","iopub.status.idle":"2025-05-02T08:44:37.665238Z","shell.execute_reply.started":"2025-05-02T08:44:37.659890Z","shell.execute_reply":"2025-05-02T08:44:37.664369Z"}},"outputs":[{"name":"stdout","text":"Mein Name ist Ziad. Ich bin zweiundzwanzig Jahre alt\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}